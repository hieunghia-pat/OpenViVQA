TASK: OpenEndedTask

DATASET:
  FEATURE_DATASET:
    TYPE: OcrFeatureDataset
    BATCH_SIZE: 64
    WORKERS: 2
    FEATURE_PATH:
      FEATURES: features\OpenViVQA\vinvl_vinvl
      SCENE_TEXT: features\OpenViVQA\swintextspotter
      IMAGE: null
    SCENE_TEXT_THRESHOLD: 0.0
    MAX_SCENE_TEXT: 100
    WORD_EMBEDDING: ViFastText
    WORD_EMBEDDING_CACHE: null
  DICT_DATASET:
    TYPE: OcrDictionaryDataset
    BATCH_SIZE: 64
    WORKERS: 2
    FEATURE_PATH:
      FEATURES: features\OpenViVQA\vinvl_vinvl
      SCENE_TEXT: features\OpenViVQA\swintextspotter
      IMAGE: null
    SCENE_TEXT_THRESHOLD: 0.0
    MAX_SCENE_TEXT: 100
    WORD_EMBEDDING: ViFastText
    WORD_EMBEDDING_CACHE: null
  MIN_FREQ: 1
  VOCAB:
    TYPE: OcrVocab
    TOKENIZER: null
    WORD_EMBEDDING: null
    WORD_EMBEDDING_CACHE: null
    MIN_FREQ: 1
    BOS_TOKEN: <bos>
    EOS_TOKEN: <eos>
    PAD_TOKEN: <pad>
    UNK_TOKEN: <unk>
    IMG_TOKEN: <img>
    FEAT_TOKEN: <feat>
    BOX_TOKEN: <box>
    OCR_TOKEN: <ocr>
    OCR_DET_TOKEN: <ocr_det>
    OCR_REC_TOKEN: <ocr_rec>
    QUESTION_TOKEN: <question>
    ANSWER_TOKEN: <answer>
    JSON_PATH:
      TRAIN: annotations\OpenViVQA\openvivqa_train_v2.json
      DEV: annotations\OpenViVQA\openvivqa_dev_v2.json
      TEST: annotations\OpenViVQA\openvivqa_test_v2.json
  JSON_PATH:
    TRAIN: annotations\OpenViVQA\openvivqa_train_v2.json
    DEV: annotations\OpenViVQA\openvivqa_dev_v2.json
    TEST: annotations\OpenViVQA\openvivqa_test_v2.json

TRAINING:
  CHECKPOINT_PATH: saved_models
  LEARNING_RATE: 1.
  RL_LEARNING_RATE: 0.000005
  WARMUP: 10000
  SCORE: CIDEr
  TRAINING_BEAM_SIZE: 5
  EVALUATING_BEAM_SIZE: 3
  PATIENCE: 5

MODEL:
  ARCHITECTURE: ReadableIterativeMCAN
  NAME: readable_iterative_mcan_region_x152++_faster_rcnn
  DEVICE: cuda
  D_MODEL: 512
  VISION_EMBEDDING:
    ARCHITECTURE: VisionOcrEmbedding
    D_OBJ_FEATURE: 1024
    D_OCR_FEATURE: 812 # 256 (det features) + 256 (rec features) + 300 (fasttext)
    D_MODEL: 512
    DROPOUT: 0.1
  TEXT_EMBEDDING:
    ARCHITECTURE: UsualEmbedding
    D_MODEL: 512
    D_EMBEDDING: 300
    DROPOUT: 0.1
    WORD_EMBEDDING: null
    WORD_EMBEDDING_CACHE: null
  SELF_ENCODER:
    ARCHITECTURE: Encoder
    D_MODEL: 512
    LAYERS: 3
    SELF_ATTENTION:
      ARCHITECTURE: ScaledDotProductAttention
      HEAD: 8
      D_MODEL: 512
      D_KEY: 64
      D_VALUE: 64
      D_FF: 2048
      D_FEATURE: 2048
      USE_AOA: False
      CAN_BE_STATEFUL: False
      DROPOUT: .1
  GUIDED_ENCODER:
    ARCHITECTURE: GuidedAttentionEncoder
    D_MODEL: 512
    LAYERS: 3
    SELF_ATTENTION:
      ARCHITECTURE: ScaledDotProductAttention
      HEAD: 8
      D_MODEL: 512
      D_KEY: 64
      D_VALUE: 64
      D_FF: 2048
      D_FEATURE: 2048
      USE_AOA: False
      CAN_BE_STATEFUL: False
      DROPOUT: .1
    GUIDED_ATTENTION:
      ARCHITECTURE: ScaledDotProductAttention
      HEAD: 8
      D_MODEL: 512
      D_KEY: 64
      D_VALUE: 64
      D_FF: 2048
      D_FEATURE: 2048
      USE_AOA: False
      CAN_BE_STATEFUL: False
      DROPOUT: .1
  MULTIMODAL_FUSION:
    D_MODEL: 512
    D_FF: 2048
    DROPOUT: .1
  DECODER:
    ARCHITECTURE: Decoder
    D_MODEL: 512
    LAYERS: 3
    ATTENTION:
      SELF_ATTENTION:
        ARCHITECTURE: ScaledDotProductAttention
        HEAD: 8
        D_MODEL: 512
        D_KEY: 64
        D_VALUE: 64
        D_FF: 2048
        D_FEATURE: 2048
        USE_AOA: False
        CAN_BE_STATEFUL: True
        DROPOUT: .1
      ENC_ATTENTION:
        ARCHITECTURE: ScaledDotProductAttention
        HEAD: 8
        D_MODEL: 512
        D_KEY: 64
        D_VALUE: 64
        D_FF: 2048
        D_FEATURE: 2048
        USE_AOA: False
        CAN_BE_STATEFUL: False
        DROPOUT: .1
    TEXT_EMBEDDING:
      ARCHITECTURE: UsualEmbedding
      D_MODEL: 512
      D_EMBEDDING: 300
      WORD_EMBEDDING: null
      WORD_EMBEDDING_CACHE: null
      DROPOUT: 0.1
