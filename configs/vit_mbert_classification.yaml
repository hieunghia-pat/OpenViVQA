TASK: ClassificationTask

DATASET:
  TYPE: MultilingualImageQuestionClassificationDataset
  BATCH_SIZE: 10
  WORKERS: 0
  MIN_FREQ: 1
  SCENE_TEXT_THRESHOLD: 0.3
  VOCAB:
    TYPE: MultilingualClassificationVocab
    TOKENIZER: null
    WORD_EMBEDDING: null
    WORD_EMBEDDING_CACHE: null
    BOS_TOKEN: <bos>
    EOS_TOKEN: <eos>
    PAD_TOKEN: <pad>
    UNK_TOKEN: <unk>
    USE_MAPPING: False
    JSON_PATH:
      TRAIN: features/OpenViVQA/annotations/OpenViVQA_train.json
      DEV: features/OpenViVQA/annotations/OpenViVQA_dev.json
      TEST: features/OpenViVQA/annotations/OpenViVQA_test.json
  JSON_PATH:
    TRAIN: features/EVJVQA/annotations/evjvqa_train.json
    DEV: features/EVJVQA/annotations/evjvqa_dev.json
    TEST: features/EVJVQA/annotations/evjvqa_public_test.json
  FEATURE_PATH:
    FEATURES: null
    SCENE_TEXT: null
    IMAGE: features/EVJVQA/images

TRAINING:
  CHECKPOINT_PATH: saved_models
  LEARNING_RATE: 0.001
  RL_LEARNING_RATE: 0.000005
  WARMUP: 10000
  SCORE: CIDEr
  TRAINING_BEAM_SIZE: 5
  EVALUATING_BEAM_SIZE: 3
  PATIENCE: 5

MODEL:
  ARCHITECTURE: ViTmBERTClassification
  NAME: vit_mbert_classification
  DEVICE: cuda
  VISION_EMBEDDING:
    ARCHITECTURE: ViTEmbedding
    PRETRAINED_NAME: google/vit-base-patch16-224-in21k
    DEVICE: cuda
    D_PRETRAINED_FEATURE: 768
    D_MODEL: 512
    DROPOUT: .1
  TEXT_EMBEDDING:
    ARCHITECTURE: BertEmbedding
    PRETRAINED_NAME: bert-base-multilingual-uncased
    DEVICE: cuda
    D_PRETRAINED_FEATURE: 768
    D_MODEL: 512
    DROPOUT: .1
  D_MODEL: 512
  DROPOUT: .1