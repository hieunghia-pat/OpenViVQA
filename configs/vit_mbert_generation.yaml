TASK: VlspEvjVqaTask

DATASET:
  FEATURE_DATASET:
    TYPE: MultilingualImageQuestionDataset
    BATCH_SIZE: 60
    WORKERS: 2
    FEATURE_PATH:
      FEATURES: features/EVJVQA/vit
      IMAGE: data/images
  DICT_DATASET:
    TYPE: MultilingualImageQuestionDictionaryDataset
    BATCH_SIZE: 60
    WORKERS: 2
    FEATURE_PATH:
      FEATURES: features/EVJVQA/vit
      IMAGE: data/images
  MIN_FREQ: 5
  VOCAB:
    TYPE: VlspEvjVqaVocab
    TOKENIZER: null
    MIN_FREQ: 5
    WORD_EMBEDDING: null
    WORD_EMBEDDING_CACHE: null
    BOS_TOKEN: <bos>
    EOS_TOKEN: <eos>
    PAD_TOKEN: <pad>
    UNK_TOKEN: <unk>
    JSON_PATH:
      TRAIN: data/evjvqa_train.json
      DEV: data/evjvqa_dev.json
      PUBLIC_TEST: data/evjvqa_public_test.json
      PRIVATE_TEST: data/evjvqa_private_test.json
  JSON_PATH:
    TRAIN: data/evjvqa_train.json
    DEV: data/evjvqa_dev.json
    PUBLIC_TEST: data/evjvqa_public_test.json
    PRIVATE_TEST: data/evjvqa_private_test.json

TRAINING:
  CHECKPOINT_PATH: saved_models
  LEARNING_RATE: 1
  RL_LEARNING_RATE: 0.000005
  WARMUP: 10000
  SCORE: CIDEr
  TRAINING_BEAM_SIZE: 5
  EVALUATING_BEAM_SIZE: 3
  PATIENCE: 5

MODEL:
  ARCHITECTURE: ViTmBERTGeneration
  NAME: vit_mbert_generation
  DEVICE: cpu
  VISION_EMBEDDING:
    ARCHITECTURE: ViTEmbedding
    PRETRAINED_NAME: google/vit-base-patch16-224-in21k
    DEVICE: cpu
    D_PRETRAINED_FEATURE: 768
    D_MODEL: 512
    DROPOUT: .1
  TEXT_EMBEDDING:
    ARCHITECTURE: BertEmbedding
    PRETRAINED_NAME: bert-base-multilingual-uncased
    DEVICE: cpu
    HIDDEN_SIZE: 768
    NUM_HIDDEN_LAYERS: 12
    NUM_ATTENTION_HEADS: 12
    LOAD_PRETRAINED: False
    FREEZE_WEIGHTS: False
    D_MODEL: 512
    DROPOUT: .1
  D_MODEL: 512
  DROPOUT: .1
  DECODER:
    ARCHITECTURE: Decoder
    D_MODEL: 512
    LAYERS: 3
    SELF_ATTENTION:
      ARCHITECTURE: ScaledDotProductAttention
      HEAD: 8
      D_MODEL: 512
      D_KEY: 64
      D_VALUE: 64
      D_FF: 2048
      D_FEATURE: 2048
      USE_AOA: False
      CAN_BE_STATEFUL: True
      DROPOUT: .1
    ENC_ATTENTION:
      ARCHITECTURE: ScaledDotProductAttention
      HEAD: 8
      D_MODEL: 512
      D_KEY: 64
      D_VALUE: 64
      D_FF: 2048
      D_FEATURE: 2048
      USE_AOA: False
      CAN_BE_STATEFUL: False
      DROPOUT: .1
    TEXT_EMBEDDING:
      ARCHITECTURE: UsualEmbedding
      D_MODEL: 512
      D_EMBEDDING: 300
      WORD_EMBEDDING: null
      WORD_EMBEDDING_CACHE: null
      DROPOUT: 0.1
    PFF:
      D_MODEL: 512
      D_FF: 2048
      DROPOUT: 0.1